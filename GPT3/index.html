<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Question Generation with GPT3 + Creative Prompting | Ritesh Yadav</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Question Generation with GPT3 + Creative Prompting" />
<meta name="author" content="Ritesh Yadav" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Performing Some Task using GPT-3" />
<meta property="og:description" content="Performing Some Task using GPT-3" />
<link rel="canonical" href="https://dark-art108.github.io/Ritesh_Yadav/GPT3/" />
<meta property="og:url" content="https://dark-art108.github.io/Ritesh_Yadav/GPT3/" />
<meta property="og:site_name" content="Ritesh Yadav" />
<meta property="og:image" content="https://dark-art108.github.io/Ritesh_Yadav/images/gpt-3.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-01-13T00:00:00-06:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://dark-art108.github.io/Ritesh_Yadav/images/gpt-3.png" />
<meta property="twitter:title" content="Question Generation with GPT3 + Creative Prompting" />
<script type="application/ld+json">
{"url":"https://dark-art108.github.io/Ritesh_Yadav/GPT3/","@type":"BlogPosting","headline":"Question Generation with GPT3 + Creative Prompting","dateModified":"2022-01-13T00:00:00-06:00","datePublished":"2022-01-13T00:00:00-06:00","image":"https://dark-art108.github.io/Ritesh_Yadav/images/gpt-3.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://dark-art108.github.io/Ritesh_Yadav/GPT3/"},"author":{"@type":"Person","name":"Ritesh Yadav"},"description":"Performing Some Task using GPT-3","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/Ritesh_Yadav/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://dark-art108.github.io/Ritesh_Yadav/feed.xml" title="Ritesh Yadav" /><link rel="shortcut icon" type="image/x-icon" href="/Ritesh_Yadav/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/Ritesh_Yadav/">Ritesh Yadav</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/Ritesh_Yadav/about/">About Me</a><a class="page-link" href="/Ritesh_Yadav/authoring/">Authoring</a><a class="page-link" href="/Ritesh_Yadav/education/">Education</a><a class="page-link" href="/Ritesh_Yadav/interviews/">Interviews</a><a class="page-link" href="/Ritesh_Yadav/research/">Research</a><a class="page-link" href="/Ritesh_Yadav/talksseminarsworkshops/">Talks/Seminars/Workshops</a><a class="page-link" href="/Ritesh_Yadav/xyz/">XYZ</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Question Generation with GPT3 + Creative Prompting</h1><p class="page-description">Performing Some Task using GPT-3</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-01-13T00:00:00-06:00" itemprop="datePublished">
        Jan 13, 2022
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Ritesh Yadav</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      8 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/Ritesh_Yadav/categories/#nlp">nlp</a>
        &nbsp;
      
        <a class="category-tags-link" href="/Ritesh_Yadav/categories/#gpt3">gpt3</a>
        &nbsp;
      
        <a class="category-tags-link" href="/Ritesh_Yadav/categories/#question generation">question generation</a>
        &nbsp;
      
        <a class="category-tags-link" href="/Ritesh_Yadav/categories/#prompt engineering">prompt engineering</a>
        
      
      </p>
    

    
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h2"><a href="#Install-OpenAI-Python-SDK">Install OpenAI Python SDK </a></li>
<li class="toc-entry toc-h2"><a href="#Few-shot-prompting-with-question-templates">Few-shot prompting with question templates </a>
<ul>
<li class="toc-entry toc-h4"><a href="#1.-Fill-in-the-blanks">1. Fill in the blanks </a></li>
<li class="toc-entry toc-h4"><a href="#2.-MCQ---Multiple-Choice-Questions">2. MCQ - Multiple Choice Questions </a></li>
<li class="toc-entry toc-h4"><a href="#3.-True-or-False-/-Boolean-Questions">3. True or False / Boolean Questions </a></li>
<li class="toc-entry toc-h4"><a href="#4.-(Just-for-fun)-Lets-try-generating-higher-order-probing-questions-which-either-needs-common-sense-or-deeper-inference.">4. (Just for fun) Lets try generating higher-order probing questions which either needs common sense or deeper inference. </a></li>
<li class="toc-entry toc-h3"><a href="#Important-Note">Important Note </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022-01-13-Question_Generation_with_GPT3_+_Creative_Prompting.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Install-OpenAI-Python-SDK">
<a class="anchor" href="#Install-OpenAI-Python-SDK" aria-hidden="true"><span class="octicon octicon-link"></span></a>Install OpenAI Python SDK<a class="anchor-link" href="#Install-OpenAI-Python-SDK"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">openai</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Collecting openai
  Downloading openai-0.11.5.tar.gz (466 kB)
     |████████████████████████████████| 466 kB 11.7 MB/s 
Requirement already satisfied: requests&gt;=2.20 in /usr/local/lib/python3.7/dist-packages (from openai) (2.23.0)
Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from openai) (4.62.3)
Collecting pandas&gt;=1.2.3
  Downloading pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)
     |████████████████████████████████| 11.3 MB 42.7 MB/s 
Collecting pandas-stubs&gt;=1.1.0.11
  Downloading pandas_stubs-1.2.0.40-py3-none-any.whl (161 kB)
     |████████████████████████████████| 161 kB 48.3 MB/s 
Collecting openpyxl&gt;=3.0.7
  Downloading openpyxl-3.0.9-py2.py3-none-any.whl (242 kB)
     |████████████████████████████████| 242 kB 52.7 MB/s 
Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl&gt;=3.0.7-&gt;openai) (1.1.0)
Requirement already satisfied: python-dateutil&gt;=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas&gt;=1.2.3-&gt;openai) (2.8.2)
Requirement already satisfied: numpy&gt;=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas&gt;=1.2.3-&gt;openai) (1.19.5)
Requirement already satisfied: pytz&gt;=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas&gt;=1.2.3-&gt;openai) (2018.9)
Requirement already satisfied: typing-extensions&gt;=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pandas-stubs&gt;=1.1.0.11-&gt;openai) (3.10.0.2)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil&gt;=2.7.3-&gt;pandas&gt;=1.2.3-&gt;openai) (1.15.0)
Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.20-&gt;openai) (2.10)
Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.20-&gt;openai) (3.0.4)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.20-&gt;openai) (2021.10.8)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.20-&gt;openai) (1.24.3)
Building wheels for collected packages: openai
  Building wheel for openai (setup.py) ... done
  Created wheel for openai: filename=openai-0.11.5-py3-none-any.whl size=161464 sha256=604ae3e818b3dc26bade5925151a4404156543dd2fee70dd437372e651bb86ee
  Stored in directory: /root/.cache/pip/wheels/5a/52/66/06c234d9748d81b9622d0b9765c3bd10e99d059ed93f13b0b3
Successfully built openai
Installing collected packages: pandas-stubs, pandas, openpyxl, openai
  Attempting uninstall: pandas
    Found existing installation: pandas 1.1.5
    Uninstalling pandas-1.1.5:
      Successfully uninstalled pandas-1.1.5
  Attempting uninstall: openpyxl
    Found existing installation: openpyxl 2.5.9
    Uninstalling openpyxl-2.5.9:
      Successfully uninstalled openpyxl-2.5.9
<span class="ansi-red-fg">ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
google-colab 1.0.0 requires pandas~=1.1.0; python_version &gt;= "3.0", but you have pandas 1.3.5 which is incompatible.</span>
Successfully installed openai-0.11.5 openpyxl-3.0.9 pandas-1.3.5 pandas-stubs-1.2.0.40
</pre>
</div>
</div>

<div class="output_area">




</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Few-shot-prompting-with-question-templates">
<a class="anchor" href="#Few-shot-prompting-with-question-templates" aria-hidden="true"><span class="octicon octicon-link"></span></a>Few-shot prompting with question templates<a class="anchor-link" href="#Few-shot-prompting-with-question-templates"> </a>
</h2>
<hr>
<p>⚡ <strong>The Idea</strong></p>
<p>For each question type (see below), Create nice reusable question templates with few examples.</p>
<ul>
<li>Fill in the blanks</li>
<li>MCQs</li>
<li>True or False / Boolean</li>
<li>Multi-choice/Multiple Fill in the blanks</li>
</ul>
<p>Question templates are a combination of prompt tokens and question phrases. For the question generation task "Few" in the phrase "few examples" depends on the question type. For instance you will witness for Fill in the lanks and MCQs 2 examples works just fine. For True or False you could just go with 1 example and May be in your experiments you may discover Zero-short can be put to best use for your needs.</p>
<p><strong>Note:</strong></p>
<ul>
<li>Here examples simply mean string templates of some static knowledge put together to match the desired Question (and answer) style.</li>
<li>Having categories of templates can help, because the closer your templates are with the actual paragraphs you are using to generate question in terms of domains the stronger will be the generation results.</li>
</ul>
<p><strong>Disclaimer:</strong></p>
<ul>
<li>The strength and quality of your generations are a function of your Prompt Tokens and Example phrases. Choose creative yet relevant prompt tokens.</li>
<li>PROMPT PROGRAMMING is a SKILL you can improve purely by TRIAL AND ERROR with your ENGLISH knowledge. </li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="1.-Fill-in-the-blanks">
<a class="anchor" href="#1.-Fill-in-the-blanks" aria-hidden="true"><span class="octicon octicon-link"></span></a>1. Fill in the blanks<a class="anchor-link" href="#1.-Fill-in-the-blanks"> </a>
</h4>
<hr>
<p><strong>Below is a sample prompt template for Fill in the blank questions</strong> As said before the examples are based on the some static knowledge. Here we have 2 <code>&lt;Paragraph/Ques-Ans&gt;</code> pairs. You can have as many example as you want. In this example <code>Paragraph:, Question:, Answer:</code> are the 3 prompt tokens.</p>
<ul>
<li>Line 1. Paragraph: Jesus, according to some biblical sources, was born in this town some two millennia ago in Bethlehem. </li>
<li>Line 2. Question: Where was Jesus born <strong>__</strong> ? Answer: Bethlehem </li>
<li>Line 3. Paragraph: Sachin Tendulkar was born in India. He debuted for Indian cricket in 1988. </li>
<li>Line 4. Question: In <strong>__</strong> Sachin started playing cricket? Answer: 1988</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">openai</span>
<span class="n">openai</span><span class="o">.</span><span class="n">api_key</span> <span class="o">=</span> <span class="s2">"&lt;your_openai_api_key&gt;"</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">prompt_template</span><span class="o">=</span> <span class="s2">"""</span>
<span class="s2">Paragraph: Jesus, according to some biblical sources, was born in this town some two millennia ago in Bethlehem. </span>
<span class="s2">Question: Where was Jesus born ______ ? Answer: Bethlehem</span>
<span class="s2">Paragraph: Sachin Tendulkar was born in India. He debuted for Indian cricket in 1988. </span>
<span class="s2">Question: In ______ Sachin started playing cricket. Answer: 1988</span>
<span class="s2">"""</span>

<span class="n">custom_prompt</span><span class="o">=</span><span class="s2">"""</span>
<span class="s2">Paragraph: Elon Musk was a born in South Africa in 1971 and he joined Tesla in 2004.</span>
<span class="s2">"""</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="n">prompt_template</span> <span class="o">+</span> <span class="n">custom_prompt</span>
<span class="n">completion</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">Completion</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">engine</span><span class="o">=</span><span class="s2">"davinci"</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span> <span class="n">max_tokens</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Generated Question.."</span><span class="p">)</span>
<span class="n">generated</span> <span class="o">=</span> <span class="n">completion</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span>
<span class="k">if</span> <span class="s2">"Paragraph"</span> <span class="ow">in</span> <span class="n">generated</span><span class="p">:</span>
   <span class="n">ind</span> <span class="o">=</span> <span class="n">generated</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">"Paragraph"</span><span class="p">)</span> 
   <span class="nb">print</span><span class="p">(</span><span class="n">generated</span><span class="p">[:</span><span class="n">ind</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Generated Question..
Question: In ______ Elon Musk joined Tesla.
Answer: 2004


</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="2.-MCQ---Multiple-Choice-Questions">
<a class="anchor" href="#2.-MCQ---Multiple-Choice-Questions" aria-hidden="true"><span class="octicon octicon-link"></span></a>2. MCQ - Multiple Choice Questions<a class="anchor-link" href="#2.-MCQ---Multiple-Choice-Questions"> </a>
</h4>
<hr>
<p><strong>Below is a sample prompt template for MCQs</strong> As said before the examples are based on the some static knowledge. Here we have 2 <code>&lt;Paragraph/Ques-Choice-Ans&gt;</code> pairs. You can have as many as you want to make the generation strong.</p>
<ul>
<li>Line 1. Paragraph: Jesus, according to some biblical sources, was born in this town some two millennia ago in Bethlehem. The story begins with wise men who come to the city of Jerusalem after seeing a star that they interpreted as signaling the birth of a new king.</li>
<li>Line 2. Question: Where was Jesus born ? A) Jerusalem, B) Palestine, C) Bethlehem. D) Tel-Aviv Answer: C</li>
<li>Line 3. Paragraph: Sachin Tendulkar was born in India 1972. He debuted for Indian cricket in 1988 and retired in 2011.</li>
<li>Line 4. Question: In what year Sachin started playing cricket? A) 1972, B) 1988, C) 2011, D) 2001. Answer: B</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">prompt_template</span><span class="o">=</span> <span class="s2">"""</span>
<span class="s2">Paragraph: Jesus, according to some biblical sources, was born in this town some two millennia ago in Bethlehem. The story begins with wise men who come to the city of Jerusalem after seeing a star that they interpreted as signaling the birth of a new king.</span>
<span class="s2">Question: Where was Jesus born ? A) Jerusalem, B) Palestine, C) Bethlehem. D) Tel-Aviv Answer: C</span>
<span class="s2">Paragraph: Sachin Tendulkar was born in India 1972. He debuted for Indian cricket in 1988 and retired in 2011.</span>
<span class="s2">Question: In what year Sachin started playing cricket? A) 1972, B) 1988, C) 2011, D) 2001. Answer: B</span>
<span class="s2">"""</span>

<span class="n">custom_prompt</span><span class="o">=</span><span class="s2">"""</span>
<span class="s2">Paragraph: Elon Musk was a born in South Africa in 1971 and he joined Tesla in 2004.</span>
<span class="s2">"""</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="n">prompt_template</span> <span class="o">+</span> <span class="n">custom_prompt</span>
<span class="n">completion</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">Completion</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">engine</span><span class="o">=</span><span class="s2">"davinci"</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span> <span class="n">max_tokens</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Generated Question.."</span><span class="p">)</span>
<span class="n">generated</span> <span class="o">=</span> <span class="n">completion</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span>
<span class="k">if</span> <span class="s2">"Paragraph"</span> <span class="ow">in</span> <span class="n">generated</span><span class="p">:</span>
   <span class="n">ind</span> <span class="o">=</span> <span class="n">generated</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">"Paragraph"</span><span class="p">)</span> 
   <span class="nb">print</span><span class="p">(</span><span class="n">generated</span><span class="p">[:</span><span class="n">ind</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Generated Question..
Question: In what year did Elon join Tesla? A) 1971, B) 2004, C) 1992, D) 2012. Answer: B

</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="3.-True-or-False-/-Boolean-Questions">
<a class="anchor" href="#3.-True-or-False-/-Boolean-Questions" aria-hidden="true"><span class="octicon octicon-link"></span></a>3. True or False / Boolean Questions<a class="anchor-link" href="#3.-True-or-False-/-Boolean-Questions"> </a>
</h4>
<hr>
<p>Here we have ONLY 1 <code>&lt;Paragraph/Ques-Ans&gt;</code> pair.  But be warned generation might suffer. More the examples in your template Stronger the generations.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">prompt_template</span><span class="o">=</span> <span class="s2">"""</span>
<span class="s2">Paragraph: Jesus, according to some biblical sources, was born in this town some two millennia ago in Bethlehem. The story begins with wise men who come to the city of Jerusalem after seeing a star that they interpreted as signaling the birth of a new king.</span>
<span class="s2">Question: Jesus was born in Jerusalem. Answer: False</span>
<span class="s2">"""</span>

<span class="n">custom_prompt</span><span class="o">=</span><span class="s2">"""</span>
<span class="s2">Paragraph: Elon Musk was a born in South Africa in 1971 and he joined Tesla in 2004.</span>
<span class="s2">"""</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="n">prompt_template</span> <span class="o">+</span> <span class="n">custom_prompt</span>
<span class="n">completion</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">Completion</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">engine</span><span class="o">=</span><span class="s2">"davinci"</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span> <span class="n">max_tokens</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Generated Question.."</span><span class="p">)</span>
<span class="n">generated</span> <span class="o">=</span> <span class="n">completion</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span>
<span class="k">if</span> <span class="s2">"Paragraph"</span> <span class="ow">in</span> <span class="n">generated</span><span class="p">:</span>
   <span class="n">ind</span> <span class="o">=</span> <span class="n">generated</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">"Paragraph"</span><span class="p">)</span> 
   <span class="nb">print</span><span class="p">(</span><span class="n">generated</span><span class="p">[:</span><span class="n">ind</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Generated Question..
Question: Elon Musk was born in Cape Town.
Answer: True


</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="4.-(Just-for-fun)-Lets-try-generating-higher-order-probing-questions-which-either-needs-common-sense-or-deeper-inference.">
<a class="anchor" href="#4.-(Just-for-fun)-Lets-try-generating-higher-order-probing-questions-which-either-needs-common-sense-or-deeper-inference." aria-hidden="true"><span class="octicon octicon-link"></span></a>4. (Just for fun) Lets try generating higher-order probing questions which either needs common sense or deeper inference.<a class="anchor-link" href="#4.-(Just-for-fun)-Lets-try-generating-higher-order-probing-questions-which-either-needs-common-sense-or-deeper-inference."> </a>
</h4>
<hr>
<p>Note how we changed the prompt strings to <code>&lt;fact/probe-inference&gt;</code> pairs</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">prompt_template</span><span class="o">=</span> <span class="s2">"""</span>
<span class="s2">Fact: Jesus, according to some biblical sources, was born in this town some two millennia ago in Bethlehem. The story begins with wise men who come to the city of Jerusalem after seeing a star that they interpreted as signaling the birth of a new king.</span>
<span class="s2">Probe: Is Jesus a human being? Inference: No he is a God.</span>
<span class="s2">Fact: Sachin Tendulkar was born in India 1972. He debuted for Indian cricket in 1988 and retired in 2011.</span>
<span class="s2">Probe: How many years Sachin played cricket? Inference: 23 years.</span>
<span class="s2">"""</span>

<span class="n">custom_prompt</span><span class="o">=</span><span class="s2">"""</span>
<span class="s2">Fact: Elon Musk started Tesla Motors since 2004. He is the CEO and product architect of Tesla and he is also the Chairman of Musk Foundation, an organization supporting research on renewable energy, human space exploration and pediatrics. At age 12, sold his code for a video game called “Blastar” to a computer magazine for $500.</span>
<span class="s2">"""</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="n">prompt_template</span> <span class="o">+</span> <span class="n">custom_prompt</span>
<span class="n">completion</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">Completion</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">engine</span><span class="o">=</span><span class="s2">"davinci"</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span> <span class="n">max_tokens</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Generated Probe.."</span><span class="p">)</span>
<span class="n">generated</span> <span class="o">=</span> <span class="n">completion</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span>
<span class="k">if</span> <span class="s2">"Fact"</span> <span class="ow">in</span> <span class="n">generated</span><span class="p">:</span>
   <span class="n">ind</span> <span class="o">=</span> <span class="n">generated</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">"Fact"</span><span class="p">)</span> 
   <span class="nb">print</span><span class="p">(</span><span class="n">generated</span><span class="p">[:</span><span class="n">ind</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Generated Probe..
Probe: What is Musk's current age? Inference: 41 years.


</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Important-Note">
<a class="anchor" href="#Important-Note" aria-hidden="true"><span class="octicon octicon-link"></span></a>Important Note<a class="anchor-link" href="#Important-Note"> </a>
</h3>
<ul>
<li>Signup for OpenAI to get your own API key !</li>
<li>Engine choice: Davinci is not the only engine of choice 
<pre><code># list engines
engines = openai.Engine.list()</code></pre>
Play with the list using the above snippet and choose the one that best suits your case.</li>
<li>Number of generations - As you can see, I have limited my generations to only 1. You could iterate over many generations with single prompt</li>
<li>Play with misc Parameters like <code>max_tokens=32, temperature=0.7</code> Refer this link  -<a href="https://beta.openai.com/docs/api-reference/completions/create">https://beta.openai.com/docs/api-reference/completions/create</a>
</li>
<li>Feel free to use your creativity and rxpand to other tasks</li>
</ul>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="DARK-art108/Ritesh_Yadav"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/Ritesh_Yadav/GPT3/" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/Ritesh_Yadav/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/Ritesh_Yadav/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/Ritesh_Yadav/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>NLP, Deep Learning, Computer Vision and MLOps</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/fastai" target="_blank" title="fastai"><svg class="svg-icon grey"><use xlink:href="/Ritesh_Yadav/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/fastdotai" target="_blank" title="fastdotai"><svg class="svg-icon grey"><use xlink:href="/Ritesh_Yadav/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
